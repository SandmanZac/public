# Allow SSH to root via keys (without-password)
cat >/etc/yum.repos.d/epel.repo <<EOL
[epel]
name=Extra Packages for Enterprise Linux $releasever - $basearch
baseurl=https://dl.fedoraproject.org/pub/epel/8/Everything/x86_64/
enabled=1
gpgcheck=0
EOL

cat >/etc/yum.repos.d/ganesha.repo <<EOL
[ganesha]
name=NFS Ganesha 3 Packages for Enterprise Linux $releasever - $basearch
baseurl=https://buildlogs.centos.org/centos/8/storage/x86_64/nfsganesha-3/
enabled=1
gpgcheck=0
EOL

cat >/etc/yum.repos.d/gluster.repo <<EOL
[gluster]
name=Gluster 9 Packages for Enterprise Linux $releasever - $basearch
baseurl=https://buildlogs.centos.org/centos/8/storage/x86_64/gluster-9/
enabled=1
gpgcheck=0
EOL

subscription-manager repos --enable=rhel-8-for-x86_64-highavailability-rpms
yum install -y glusterfs-server glusterfs-ganesha ctdb network-scripts
firewall-cmd --add-service={glusterfs,nfs,nfs3,mountd,rpc-bind} --permanent
firewall-cmd --add-port=4379/tcp  --permanent
firewall-cmd --reload
mkdir /nfs
fdisk -l /dev/sdb
pvcreate /dev/sdb
vgcreate vg00 /dev/sdb
lvcreate -L 4.5G -n lv00 vg00
mkfs.xfs -f -i size=512 -n size=8192 -d su=128k,sw=10 /dev/mapper/vg00-lv00 
device="/dev/mapper/vg00-lv00"
mountpoint="/nfs"
options="xfs rw,inode64,noatime,nouuid 1 2"
echo "$device $mountpoint $options" >> /etc/fstab
mount /nfs

systemctl start glusterd
systemctl start glusterfsd
systemctl start glusterfssharedstorage

# The following is all done from nfs1
gluster peer probe nfs2.caz.one
gluster volume create gv00 transport tcp replica 2 nfs1.caz.one:/nfs/gv00 nfs2.caz.one:/nfs/gv00
gluster volume set gv00 features.trash on
gluster volume set gv00 storage.linux-io_uring on
gluster volume set gv00 group metadata-cache
gluster volume set gv00 performance.readdir-ahead on
gluster volume set gv00 performance.parallel-readdir on
gluster volume set gv00 group nl-cache
gluster volume set gv00 nl-cache-positive-entry on
gluster volume set gv00 nfs.acl on
gluster volume start gv00
# If we have a lot of small files being read
gluster volume stop gv00
gluster volume set gv00 performance.cache-invalidation on
gluster volume set gv00 features.cache-invalidation on
gluster volume set gv00 performance.qr-cache-timeout 600 # 10 min recommended setting
gluster volume set gv00 cache-invalidation-timeout 600 # 10 min recommended setting
gluster volume start gv00

# Switch from NetworkManager to network-scripts
systemctl enable network.service
systemctl stop NetworkManager
systemctl disable NetworkManager
echo "NM_CONTROLLED=\"no\"" >> /etc/sysconfig/network-scripts/ifcfg-ens3
systemctl restart network.service

gluster volume set all cluster.enable-shared-storage enable

setsebool -P daemons_enable_cluster_mode 1
systemctl enable pcsd.service
systemctl start pcsd.service
systemctl enable corosync.service
firewall-cmd --permanent --add-service=high-availability; firewall-cmd --reload

# create SSH keys for both nodes and add them to /root/.ssh/authorized_keys
# /root/.ssh should be 700
# /root/.ssh/authorized_keys should be 600

# on all nodes set the password for hacluster to the same password
# passwd hacluster

pcs host auth nfs1 nfs2
